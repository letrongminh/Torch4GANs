{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer for TimeSeries Forecast 01.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO+weRojqmMo739CMAb0Z/Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/letrongminh/Torch4GANs/blob/main/Transformer_for_TimeSeries_Forecast_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTMs xử lý thông tin tuần tự, như được hiển thị ở trên. Kiến trúc này duy trì trạng thái ẩn được cập nhật với mọi mã thông báo đầu vào mới, đại diện cho toàn bộ trình tự mà nó đã thấy. Về mặt lý thuyết, thông tin rất quan trọng có thể lan truyền qua các chuỗi dài vô hạn. Tuy nhiên, trong thực tế, điều này không đúng như vậy. Do vấn đề về Vanishing Gradient, LSTM cuối cùng sẽ quên các thông tin trước đó."
      ],
      "metadata": {
        "id": "fFsv2NcRfr_v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trong khi đó, Transformers giữ lại các kết nối trực tiếp với tất cả các thời gian trước đó, cho phép thông tin truyền qua các chuỗi dài hơn nhiều. Tuy nhiên, điều này đòi hỏi một thách thức mới: mô hình sẽ được kết nối trực tiếp với một lượng đầu vào bùng nổ. Để lọc điều quan trọng khỏi điều không quan trọng, Transformers sử dụng một thuật toán gọi là tự chú ý."
      ],
      "metadata": {
        "id": "30DYQj9xgiou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Self-Attention**\n",
        "\n",
        "Cơ chế chú ý được thiết kế để chỉ tập trung vào các tập hợp con quan trọng nhất của các chuỗi dài tùy ý, có liên quan để hoàn thành một nhiệm vụ nhất định.\n",
        "\n",
        "Cụ thể, mô hình phải quyết định những chi tiết nào từ các thẻ nhớ trước đó có liên quan để mã hóa mã thông báo hiện tại. Khối tự chú ý mã hóa từng đầu vào mới đối với tất cả các đầu vào khác trước đó, đặt trọng tâm dựa trên tính toán mức độ liên quan đối với mã thông báo hiện tại.\n",
        "\n"
      ],
      "metadata": {
        "id": "JzzrYyxeg_-2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0YwxB5QfKqg",
        "outputId": "ad3f967f-9292-48ca-e728-56721ed05d23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Handle/ Data Loader"
      ],
      "metadata": {
        "id": "4lQfS9hnqBES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install icecream"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J72J0Ay7qTVj",
        "outputId": "07f33eed-18f7-4295-e1ee-8ff808625344"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting icecream\n",
            "  Downloading icecream-2.1.1-py2.py3-none-any.whl (8.1 kB)\n",
            "Collecting executing>=0.3.1\n",
            "  Downloading executing-0.8.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting colorama>=0.3.9\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from icecream) (2.6.1)\n",
            "Collecting asttokens>=2.0.1\n",
            "  Downloading asttokens-2.0.5-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from asttokens>=2.0.1->icecream) (1.15.0)\n",
            "Installing collected packages: executing, colorama, asttokens, icecream\n",
            "Successfully installed asttokens-2.0.5 colorama-0.4.4 executing-0.8.2 icecream-2.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from joblib import dump\n",
        "\n",
        "from icecream import ic\n",
        "import time\n",
        "import datetime\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "import logging\n",
        "from joblib import load\n"
      ],
      "metadata": {
        "id": "vO9ofbtSp36V"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SensorDataset(Dataset):\n",
        "  \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "  def __init__(self, csv_name, root_dir, training_length, forecast_window):\n",
        "      \"\"\"\n",
        "      Args:\n",
        "          csv_file (string): Path to the csv file.\n",
        "          root_dir (string): Directory\n",
        "      \"\"\"\n",
        "      \n",
        "      # load raw data file\n",
        "      csv_file = os.path.join(root_dir, csv_name)\n",
        "      self.df = pd.read_csv(csv_file)\n",
        "      self.root_dir = root_dir\n",
        "      self.transform = MinMaxScaler()\n",
        "      self.T = training_length\n",
        "      self.S = forecast_window\n",
        "\n",
        "  def __len__(self):\n",
        "      # return number of sensors\n",
        "      return len(self.df.groupby(by=[\"reindexed_id\"]))\n",
        "\n",
        "  # Will pull an index between 0 and __len__. \n",
        "  def __getitem__(self, idx):\n",
        "      \n",
        "      # Sensors are indexed from 1\n",
        "      idx = idx+1\n",
        "\n",
        "      # np.random.seed(0)\n",
        "\n",
        "      start = np.random.randint(0, len(self.df[self.df[\"reindexed_id\"]==idx]) - self.T - self.S) \n",
        "      sensor_number = str(self.df[self.df[\"reindexed_id\"]==idx][[\"sensor_id\"]][start:start+1].values.item())\n",
        "      index_in = torch.tensor([i for i in range(start, start+self.T)])\n",
        "      index_tar = torch.tensor([i for i in range(start + self.T, start + self.T + self.S)])\n",
        "      _input = torch.tensor(self.df[self.df[\"reindexed_id\"]==idx][[\"humidity\", \"sin_hour\", \"cos_hour\", \"sin_day\", \"cos_day\", \"sin_month\", \"cos_month\"]][start : start + self.T].values)\n",
        "      target = torch.tensor(self.df[self.df[\"reindexed_id\"]==idx][[\"humidity\", \"sin_hour\", \"cos_hour\", \"sin_day\", \"cos_day\", \"sin_month\", \"cos_month\"]][start + self.T : start + self.T + self.S].values)\n",
        "\n",
        "      # scalar is fit only to the input, to avoid the scaled values \"leaking\" information about the target range.\n",
        "      # scalar is fit only for humidity, as the timestamps are already scaled\n",
        "      # scalar input/output of shape: [n_samples, n_features].\n",
        "      scaler = self.transform\n",
        "\n",
        "      scaler.fit(_input[:,0].unsqueeze(-1))\n",
        "      _input[:,0] = torch.tensor(scaler.transform(_input[:,0].unsqueeze(-1)).squeeze(-1))\n",
        "      target[:,0] = torch.tensor(scaler.transform(target[:,0].unsqueeze(-1)).squeeze(-1))\n",
        "\n",
        "      # save the scalar to be used later when inverse translating the data for plotting.\n",
        "      dump(scaler, 'scalar_item.joblib')\n",
        "\n",
        "      return index_in, index_tar, _input, target, sensor_number"
      ],
      "metadata": {
        "id": "-TyBnmufqKYk"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**"
      ],
      "metadata": {
        "id": "5LpG2hhl8D9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding the timestamp data cyclically. See Medium Article.\n",
        "def process_data(source):\n",
        "  df = pd.read_csv(source)\n",
        "      \n",
        "  timestamps = [ts.split('+')[0] for ts in  df['timestamp']]\n",
        "  timestamps_hour = np.array([float(datetime.datetime.strptime(t, '%Y-%m-%d %H:%M:%S').hour) for t in timestamps])\n",
        "  timestamps_day = np.array([float(datetime.datetime.strptime(t, '%Y-%m-%d %H:%M:%S').day) for t in timestamps])\n",
        "  timestamps_month = np.array([float(datetime.datetime.strptime(t, '%Y-%m-%d %H:%M:%S').month) for t in timestamps])\n",
        "\n",
        "  hours_in_day = 24\n",
        "  days_in_month = 30\n",
        "  month_in_year = 12\n",
        "\n",
        "  df['sin_hour'] = np.sin(2*np.pi*timestamps_hour/hours_in_day)\n",
        "  df['cos_hour'] = np.cos(2*np.pi*timestamps_hour/hours_in_day)\n",
        "  df['sin_day'] = np.sin(2*np.pi*timestamps_day/days_in_month)\n",
        "  df['cos_day'] = np.cos(2*np.pi*timestamps_day/days_in_month)\n",
        "  df['sin_month'] = np.sin(2*np.pi*timestamps_month/month_in_year)\n",
        "  df['cos_month'] = np.cos(2*np.pi*timestamps_month/month_in_year)\n",
        "\n",
        "  return df\n",
        "\n",
        "train_dataset = process_data('/content/drive/MyDrive/Colab_Notebooks_1/PyTorchtoGANs/Transformer/Data/train_raw.csv')\n",
        "test_dataset = process_data('/content/drive/MyDrive/Colab_Notebooks_1/PyTorchtoGANs/Transformer/Data/test_raw.csv')\n",
        "\n",
        "train_dataset.to_csv(r'train_dataset.csv', index=False)\n",
        "test_dataset.to_csv(r'test_dataset.csv', index=False)"
      ],
      "metadata": {
        "id": "medpfLQ17KO7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model building"
      ],
      "metadata": {
        "id": "KZbyJl2GaQwA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model**\n",
        "\n",
        "The architecture is based on the paper \"Attention is all you need\""
      ],
      "metadata": {
        "id": "tI-AWGKManxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "  # d_model : number of features\n",
        "  def __init__(self,feature_size=7,num_layers=3,dropout=0):\n",
        "      super(Transformer, self).__init__()\n",
        "\n",
        "      self.encoder_layer = nn.TransformerEncoderLayer(d_model=feature_size, nhead=7, dropout=dropout)\n",
        "      self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)        \n",
        "      self.decoder = nn.Linear(feature_size,1)\n",
        "      self.init_weights()\n",
        "\n",
        "  def init_weights(self):\n",
        "      initrange = 0.1    \n",
        "      self.decoder.bias.data.zero_()\n",
        "      self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "  def _generate_square_subsequent_mask(self, sz):\n",
        "      mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "      mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "      return mask\n",
        "\n",
        "  def forward(self, src, device):\n",
        "      \n",
        "      mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
        "      output = self.transformer_encoder(src,mask)\n",
        "      output = self.decoder(output)\n",
        "      return output\n",
        "      "
      ],
      "metadata": {
        "id": "pcBaPd4GamGd"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**helper**"
      ],
      "metadata": {
        "id": "7kufe9imrTBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "\n",
        "# save train or validation loss\n",
        "def log_loss(loss_val : float, path_to_save_loss : str, train : bool = True):\n",
        "    if train:\n",
        "        file_name = \"train_loss.txt\"\n",
        "    else:\n",
        "        file_name = \"val_loss.txt\"\n",
        "\n",
        "    path_to_file = path_to_save_loss+file_name\n",
        "    os.makedirs(os.path.dirname(path_to_file), exist_ok=True)\n",
        "    with open(path_to_file, \"a\") as f:\n",
        "        f.write(str(loss_val)+\"\\n\")\n",
        "        f.close()\n",
        "\n",
        "# Exponential Moving Average, https://en.wikipedia.org/wiki/Moving_average\n",
        "def EMA(values, alpha=0.1):\n",
        "    ema_values = [values[0]]\n",
        "    for idx, item in enumerate(values[1:]):\n",
        "        ema_values.append(alpha*item + (1-alpha)*ema_values[idx])\n",
        "    return ema_values\n",
        "\n",
        "# Remove all files from previous executions and re-run the model.\n",
        "def clean_directory():\n",
        "\n",
        "    if os.path.exists('save_loss'):\n",
        "        shutil.rmtree('save_loss')\n",
        "    if os.path.exists('save_model'): \n",
        "        shutil.rmtree('save_model')\n",
        "    if os.path.exists('save_predictions'): \n",
        "        shutil.rmtree('save_predictions')\n",
        "    os.mkdir(\"save_loss\")\n",
        "    os.mkdir(\"save_model\")\n",
        "    os.mkdir(\"save_predictions\")"
      ],
      "metadata": {
        "id": "OvDQXNtqokyi"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot**"
      ],
      "metadata": {
        "id": "L25lyg7Brl2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss(path_to_save, train=True):\n",
        "    plt.rcParams.update({'font.size': 10})\n",
        "    with open(path_to_save + \"/train_loss.txt\", 'r') as f:\n",
        "        loss_list = [float(line) for line in f.readlines()]\n",
        "    if train:\n",
        "        title = \"Train\"\n",
        "    else:\n",
        "        title = \"Validation\"\n",
        "    EMA_loss = EMA(loss_list)\n",
        "    plt.plot(loss_list, label = \"loss\")\n",
        "    plt.plot(EMA_loss, label=\"EMA loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.title(title+\"_loss\")\n",
        "    plt.savefig(path_to_save+f\"/{title}.png\")\n",
        "    plt.close()\n",
        "\n",
        "def plot_prediction(title, path_to_save, src, tgt, prediction, sensor_number, index_in, index_tar):\n",
        "\n",
        "    idx_scr = index_in[0, 1:].tolist()\n",
        "    idx_tgt = index_tar[0].tolist()\n",
        "    idx_pred = [i for i in range(idx_scr[0] +1, idx_tgt[-1])] #t2 - t61\n",
        "\n",
        "    plt.figure(figsize=(15,6))\n",
        "    plt.rcParams.update({\"font.size\" : 16})\n",
        "\n",
        "    # connect with last elemenet in src\n",
        "    # tgt = np.append(src[-1], tgt.flatten())\n",
        "    # prediction = np.append(src[-1], prediction.flatten())\n",
        "\n",
        "    # plotting\n",
        "    plt.plot(idx_scr, src, '-', color = 'blue', label = 'Input', linewidth=2)\n",
        "    plt.plot(idx_tgt, tgt, '-', color = 'indigo', label = 'Target', linewidth=2)\n",
        "    plt.plot(idx_pred, prediction,'--', color = 'limegreen', label = 'Forecast', linewidth=2)\n",
        "\n",
        "    #formatting\n",
        "    plt.grid(b=True, which='major', linestyle = 'solid')\n",
        "    plt.minorticks_on()\n",
        "    plt.grid(b=True, which='minor', linestyle = 'dashed', alpha=0.5)\n",
        "    plt.xlabel(\"Time Elapsed\")\n",
        "    plt.ylabel(\"Humidity (%)\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Forecast from Sensor \" + str(sensor_number[0]))\n",
        "\n",
        "    # save\n",
        "    plt.savefig(path_to_save+f\"Prediction_{title}.png\")\n",
        "    plt.close()\n",
        "\n",
        "def plot_training(epoch, path_to_save, src, prediction, sensor_number, index_in, index_tar):\n",
        "\n",
        "    # idx_scr = index_in.tolist()[0]\n",
        "    # idx_tar = index_tar.tolist()[0]\n",
        "    # idx_pred = idx_scr.append(idx_tar.append([idx_tar[-1] + 1]))\n",
        "\n",
        "    idx_scr = [i for i in range(len(src))]\n",
        "    idx_pred = [i for i in range(1, len(prediction)+1)]\n",
        "\n",
        "    plt.figure(figsize=(15,6))\n",
        "    plt.rcParams.update({\"font.size\" : 18})\n",
        "    plt.grid(b=True, which='major', linestyle = '-')\n",
        "    plt.grid(b=True, which='minor', linestyle = '--', alpha=0.5)\n",
        "    plt.minorticks_on()\n",
        "\n",
        "    plt.plot(idx_scr, src, 'o-.', color = 'blue', label = 'input sequence', linewidth=1)\n",
        "    plt.plot(idx_pred, prediction, 'o-.', color = 'limegreen', label = 'prediction sequence', linewidth=1)\n",
        "\n",
        "    plt.title(\"Teaching Forcing from Sensor \" + str(sensor_number[0]) + \", Epoch \" + str(epoch))\n",
        "    plt.xlabel(\"Time Elapsed\")\n",
        "    plt.ylabel(\"Humidity (%)\")\n",
        "    plt.legend()\n",
        "    plt.savefig(path_to_save+f\"/Epoch_{str(epoch)}.png\")\n",
        "    plt.close()\n",
        "\n",
        "def plot_training_3(epoch, path_to_save, src, sampled_src, prediction, sensor_number, index_in, index_tar):\n",
        "\n",
        "    # idx_scr = index_in.tolist()[0]\n",
        "    # idx_tar = index_tar.tolist()[0]\n",
        "    # idx_pred = idx_scr.append(idx_tar.append([idx_tar[-1] + 1]))\n",
        "\n",
        "    idx_scr = [i for i in range(len(src))]\n",
        "    idx_pred = [i for i in range(1, len(prediction)+1)]\n",
        "    idx_sampled_src = [i for i in range(len(sampled_src))]\n",
        "\n",
        "    plt.figure(figsize=(15,6))\n",
        "    plt.rcParams.update({\"font.size\" : 18})\n",
        "    plt.grid(b=True, which='major', linestyle = '-')\n",
        "    plt.grid(b=True, which='minor', linestyle = '--', alpha=0.5)\n",
        "    plt.minorticks_on()\n",
        "\n",
        "    ## REMOVE DROPOUT FOR THIS PLOT TO APPEAR AS EXPECTED !! DROPOUT INTERFERES WITH HOW THE SAMPLED SOURCES ARE PLOTTED\n",
        "    plt.plot(idx_sampled_src, sampled_src, 'o-.', color='red', label = 'sampled source', linewidth=1, markersize=10)\n",
        "    plt.plot(idx_scr, src, 'o-.', color = 'blue', label = 'input sequence', linewidth=1)\n",
        "    plt.plot(idx_pred, prediction, 'o-.', color = 'limegreen', label = 'prediction sequence', linewidth=1)\n",
        "    plt.title(\"Teaching Forcing from Sensor \" + str(sensor_number[0]) + \", Epoch \" + str(epoch))\n",
        "    plt.xlabel(\"Time Elapsed\")\n",
        "    plt.ylabel(\"Humidity (%)\")\n",
        "    plt.legend()\n",
        "    plt.savefig(path_to_save+f\"/Epoch_{str(epoch)}.png\")\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "H0WLFPlHrb9c"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inference**"
      ],
      "metadata": {
        "id": "LC2ss8GVrpWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(name)s %(message)s\", datefmt=\"[%Y-%m-%d %H:%M:%S]\")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def inference(path_to_save_predictions, forecast_window, dataloader, device, path_to_save_model, best_model):\n",
        "\n",
        "    device = torch.device(device)\n",
        "    \n",
        "    model = Transformer().double().to(device)\n",
        "    model.load_state_dict(torch.load(path_to_save_model+best_model))\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "\n",
        "        model.eval()\n",
        "        for plot in range(25):\n",
        "\n",
        "            for index_in, index_tar, _input, target, sensor_number in dataloader:\n",
        "                \n",
        "                # starting from 1 so that src matches with target, but has same length as when training\n",
        "                src = _input.permute(1,0,2).double().to(device)[1:, :, :] # 47, 1, 7: t1 -- t47\n",
        "                target = target.permute(1,0,2).double().to(device) # t48 - t59\n",
        "\n",
        "                next_input_model = src\n",
        "                all_predictions = []\n",
        "\n",
        "                for i in range(forecast_window - 1):\n",
        "                    \n",
        "                    prediction = model(next_input_model, device) # 47,1,1: t2' - t48'\n",
        "\n",
        "                    if all_predictions == []:\n",
        "                        all_predictions = prediction # 47,1,1: t2' - t48'\n",
        "                    else:\n",
        "                        all_predictions = torch.cat((all_predictions, prediction[-1,:,:].unsqueeze(0))) # 47+,1,1: t2' - t48', t49', t50'\n",
        "\n",
        "                    pos_encoding_old_vals = src[i+1:, :, 1:] # 46, 1, 6, pop positional encoding first value: t2 -- t47\n",
        "                    pos_encoding_new_val = target[i + 1, :, 1:].unsqueeze(1) # 1, 1, 6, append positional encoding of last predicted value: t48\n",
        "                    pos_encodings = torch.cat((pos_encoding_old_vals, pos_encoding_new_val)) # 47, 1, 6 positional encodings matched with prediction: t2 -- t48\n",
        "                    \n",
        "                    next_input_model = torch.cat((src[i+1:, :, 0].unsqueeze(-1), prediction[-1,:,:].unsqueeze(0))) #t2 -- t47, t48'\n",
        "                    next_input_model = torch.cat((next_input_model, pos_encodings), dim = 2) # 47, 1, 7 input for next round\n",
        "\n",
        "                true = torch.cat((src[1:,:,0],target[:-1,:,0]))\n",
        "                loss = criterion(true, all_predictions[:,:,0])\n",
        "                val_loss += loss\n",
        "            \n",
        "            val_loss = val_loss/10\n",
        "            scaler = load('scalar_item.joblib')\n",
        "            src_humidity = scaler.inverse_transform(src[:,:,0].cpu())\n",
        "            target_humidity = scaler.inverse_transform(target[:,:,0].cpu())\n",
        "            prediction_humidity = scaler.inverse_transform(all_predictions[:,:,0].detach().cpu().numpy())\n",
        "            plot_prediction(plot, path_to_save_predictions, src_humidity, target_humidity, prediction_humidity, sensor_number, index_in, index_tar)\n",
        "\n",
        "        logger.info(f\"Loss On Unseen Dataset: {val_loss.item()}\")"
      ],
      "metadata": {
        "id": "uAzvOaK1r12Q"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(name)s %(message)s\", datefmt=\"[%Y-%m-%d %H:%M:%S]\")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def transformer(dataloader, EPOCH, k, frequency, path_to_save_model, path_to_save_loss, path_to_save_predictions, device):\n",
        "\n",
        "  device = torch.device(device)\n",
        "\n",
        "  model = Transformer().double().to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters())\n",
        "  # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=200)\n",
        "  criterion = torch.nn.MSELoss()\n",
        "  best_model = \"\"\n",
        "  min_train_loss = float('inf')\n",
        "\n",
        "  for epoch in range(EPOCH + 1):\n",
        "\n",
        "      train_loss = 0\n",
        "      val_loss = 0\n",
        "\n",
        "      ## TRAIN -- TEACHER FORCING\n",
        "      model.train()\n",
        "      for index_in, index_tar, _input, target, sensor_number in dataloader: # for each data set \n",
        "      \n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # Shape of _input : [batch, input_length, feature]\n",
        "          # Desired input for model: [input_length, batch, feature]\n",
        "\n",
        "          src = _input.permute(1,0,2).double().to(device)[:-1,:,:] # torch.Size([24, 1, 7])\n",
        "          target = _input.permute(1,0,2).double().to(device)[1:,:,:] # src shifted by 1.\n",
        "          prediction = model(src, device) # torch.Size([24, 1, 7])\n",
        "          loss = criterion(prediction, target[:,:,0].unsqueeze(-1))\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          # scheduler.step(loss.detach().item())\n",
        "          train_loss += loss.detach().item()\n",
        "\n",
        "      if train_loss < min_train_loss:\n",
        "          torch.save(model.state_dict(), path_to_save_model + f\"best_train_{epoch}.pth\")\n",
        "          torch.save(optimizer.state_dict(), path_to_save_model + f\"optimizer_{epoch}.pth\")\n",
        "          min_train_loss = train_loss\n",
        "          best_model = f\"best_train_{epoch}.pth\"\n",
        "\n",
        "\n",
        "      if epoch % 100 == 0: # Plot 1-Step Predictions\n",
        "\n",
        "          logger.info(f\"Epoch: {epoch}, Training loss: {train_loss}\")\n",
        "          scaler = load('scalar_item.joblib')\n",
        "          src_humidity = scaler.inverse_transform(src[:,:,0].cpu()) #torch.Size([35, 1, 7])\n",
        "          target_humidity = scaler.inverse_transform(target[:,:,0].cpu()) #torch.Size([35, 1, 7])\n",
        "          prediction_humidity = scaler.inverse_transform(prediction[:,:,0].detach().cpu().numpy()) #torch.Size([35, 1, 7])\n",
        "          plot_training(epoch, path_to_save_predictions, src_humidity, prediction_humidity, sensor_number, index_in, index_tar)\n",
        "\n",
        "      train_loss /= len(dataloader)\n",
        "      log_loss(train_loss, path_to_save_loss, train=True)\n",
        "      \n",
        "  plot_loss(path_to_save_loss, train=True)\n",
        "  return best_model"
      ],
      "metadata": {
        "id": "VDOyjgA9s5Ag"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Main**"
      ],
      "metadata": {
        "id": "kXvMWwWLsUbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "\n",
        "root = '/content/'\n",
        "\n",
        "def main( epoch = 1500, k = 60, batch_size =32 ,\n",
        "         frequency = 100, training_length = 24, forecast_window = 12, \n",
        "         train_csv = \"train_dataset.csv\", test_csv = \"test_dataset.csv\", \n",
        "         path_to_save_model = \"save_model/\", \n",
        "         path_to_save_loss = \"save_loss/\",  \n",
        "         path_to_save_predictions = \"save_predictions/\",  \n",
        "         device = \"cpu\"):\n",
        "  \n",
        "  clean_directory()\n",
        "  train_dataset = SensorDataset(csv_name = train_csv, root_dir = root, training_length = training_length, forecast_window = forecast_window)\n",
        "  train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "  test_dataset = SensorDataset(csv_name = test_csv, root_dir = root, training_length = training_length, forecast_window = forecast_window)\n",
        "  test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "  best_model = transformer(train_dataloader, epoch, k, frequency, path_to_save_model, path_to_save_loss, path_to_save_predictions, device)\n",
        "  inference(path_to_save_predictions, forecast_window, test_dataloader, device, path_to_save_model, best_model)\n",
        "\n",
        "\n",
        "main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RClyyJzsJvB",
        "outputId": "271ee384-1a37-49f8-c15c-e325d472c323"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2022-01-16 17:14:46] [INFO] __main__ Epoch: 0, Training loss: 1.4117889722778505\n",
            "[2022-01-16 17:14:57] [INFO] __main__ Epoch: 100, Training loss: 0.035739494928948096\n",
            "[2022-01-16 17:15:09] [INFO] __main__ Epoch: 200, Training loss: 0.04626071597698528\n",
            "[2022-01-16 17:15:19] [INFO] __main__ Epoch: 300, Training loss: 0.02784590172310985\n",
            "[2022-01-16 17:15:30] [INFO] __main__ Epoch: 400, Training loss: 0.026922289711511924\n",
            "[2022-01-16 17:15:41] [INFO] __main__ Epoch: 500, Training loss: 0.027998669805422607\n",
            "[2022-01-16 17:15:52] [INFO] __main__ Epoch: 600, Training loss: 0.018889757267674636\n",
            "[2022-01-16 17:16:03] [INFO] __main__ Epoch: 700, Training loss: 0.023743670195789636\n",
            "[2022-01-16 17:16:14] [INFO] __main__ Epoch: 800, Training loss: 0.04001753914921255\n",
            "[2022-01-16 17:16:25] [INFO] __main__ Epoch: 900, Training loss: 0.02659667900307344\n",
            "[2022-01-16 17:16:35] [INFO] __main__ Epoch: 1000, Training loss: 0.028530942895002395\n",
            "[2022-01-16 17:16:46] [INFO] __main__ Epoch: 1100, Training loss: 0.01849483844477611\n",
            "[2022-01-16 17:16:57] [INFO] __main__ Epoch: 1200, Training loss: 0.026749388282930903\n",
            "[2022-01-16 17:17:08] [INFO] __main__ Epoch: 1300, Training loss: 0.020670619282758325\n",
            "[2022-01-16 17:17:19] [INFO] __main__ Epoch: 1400, Training loss: 0.017420681636837177\n",
            "[2022-01-16 17:17:30] [INFO] __main__ Epoch: 1500, Training loss: 0.01833677650049401\n",
            "[2022-01-16 17:17:40] [INFO] __main__ Loss On Unseen Dataset: 0.005311708643722369\n"
          ]
        }
      ]
    }
  ]
}